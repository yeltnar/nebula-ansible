---
- name: F
  hosts: nebula_nodes
  order: reverse_inventory

  vars: 
    work_dir: /tmp/yeltnar-ansible
    nebula_ca_name: "yeltnar nebula ca"
    nebula_config_client_folder: "/etc/nebula/"
    # executable_dir # is found in vars/{os_type}/{processor_arch}
  
  # TODO make sure jq is installed
  # TODO make sure BECOME password is used 

  vars_files:
    - nebula-config.yml
    - vars/{{ansible_facts.system}}/{{ansible_facts.machine}}.yml
    - vars/orchestrator.yml # this needs to be changed to reflect the OS ansible is being ran on
    - vars/other_hosts.yml

  tasks:
    # - name: Print all available facts
    #   ansible.builtin.debug:
    #     var: ansible_facts

    # - name: write facts
    #   local_action:
    #     module: shell
    #   # shell:
    #   # sed -i s/4.20/4.x/ package.json
    #     # vars_files: 
    #     #   - vars/{{ansible_local.system}}/{{ansible_local.machine}}.yml
    
    # - name: Copy using inline content
    #   local_action:
    #     module: ansible.builtin.copy
    #     content: "{{hostvars}}"
    #     dest: /tmp/ansible.hosts.json
    #   run_once: true

    # - meta: end_play

    # install download binaries 
    - name: download binaries to orchestrator machine 
      local_action:
        module: shell
        executable: /bin/bash
        cmd: |
          version=$(curl https://api.github.com/repos/slackhq/nebula/releases/latest | jq -r .tag_name)
          
          mkdir -p "{{work_dir}}_orch"
          rm -rf {{work_dir}}_orch/*
          cd "{{work_dir}}_orch"
          
          curl -OL "https://github.com/slackhq/nebula/releases/download/$version/{{orchestrator_os_file_name}}"

          echo "$version\n{{orchestrator_os_file_name}}\n{{work_dir}}\n$PWD" > /tmp/drew_ansible.log

          PATH=$PATH:~/playin/custom_bashrc/bin

          whoami;
          pwd;

          extract {{orchestrator_os_file_name}}
        #creates: "/dev/nulll"
      run_once: true
      register: binaries_log

    # download binaries to client machines 
    - name: download binaries to client machines
      shell:
        executable: /bin/bash
        cmd: |

          version=$(curl https://api.github.com/repos/slackhq/nebula/releases/latest | jq -r .tag_name)
          
          mkdir -p {{work_dir}}
          rm -rf {{work_dir}}/*
          cd {{work_dir}}
          
          curl -OL "https://github.com/slackhq/nebula/releases/download/$version/{{os_file_name}}"

          ~/playin/custom_bashrc/bin/extract {{os_file_name}} # TODO need to be more dynamic

    - name: move binaries to bin dir (as root)
      shell:
        cmd : |
          cd {{work_dir}}
          mv nebula {{executable_dir}}/
          mv nebula-cert {{executable_dir}}/
          cd .. && rm -rf {{work_dir}}
      become: true

    # TODO maybe dont if it exists, or download from bitwarden  
    - name: create nebula ca 
      local_action:
        module: shell
        cmd: |
          cd "{{work_dir}}_orch"
          ./nebula-cert ca -name "{{nebula_ca_name}}"
        creates: "{{work_dir}}/ca.crt"
      run_once: true

    - name: create nebula directories
      local_action:
        module: shell
        cmd: |
          cd "{{work_dir}}_orch"
          mkdir -p "{{item.value.name}}"
      loop: "{{hostvars | dict2items}}"
      run_once: true

    - name: create extra nebula devices directories 
      local_action:
        module: shell
        cmd: |
          cd "{{work_dir}}_orch"
          mkdir -p "{{item.value.name}}"
      loop: "{{other_hosts | dict2items}}"
      run_once: true

    - name: create nebula certs
      local_action:
        module: shell
        cmd: |
          cd "{{work_dir}}_orch"
          mkdir -p "{{item.value.name}}"

          ./nebula-cert sign \
          -out-crt {{item.value.name}}/host.crt -out-key {{item.value.name}}/host.key \
          -name "{{item.value.name}}" \
          -ip "{{item.value.nebula_ip}}" \
          -groups "{{item.value.signed_groups}}" 
      loop: "{{hostvars | dict2items}}"
      run_once: true

    - name: create nebula certs for extra devices
      local_action:
        module: shell
        cmd: |
          cd "{{work_dir}}_orch"
          mkdir -p "{{item.value.name}}"

          ./nebula-cert sign \
          -out-crt {{item.value.name}}/host.crt \
          -out-key {{item.value.name}}/host.key \
          -name "{{item.value.name}}" \
          -ip "{{item.value.nebula_ip}}" \
          -groups "{{item.value.signed_groups}}" 
      loop: "{{other_hosts | dict2items}}"
      run_once: true

    # TODO upload certs to bitwarden; this should allow for communication assuming the overlay network is down 
    
    # create the config.yml for each host
    - name: create config for hosts
      local_action:
        module: shell
        cmd: |
          mkdir -p "{{work_dir}}_orch"
          cd "{{work_dir}}_orch"
          mkdir -p "{{item.value.name}}"
          cd "{{item.value.name}}"

          echo "{{item.value.config_changes}}" | yq -P '.' > changes.yml 

          yq eval-all '. as $item ireduce ({}; . * $item)' {{playbook_dir}}/vars/nebula_default.reduced.yml changes.yml > config.yml

      loop: "{{hostvars | dict2items}}"
      loop_control:
        loop_var: item
      run_once: true
    
    # create the config.yml for each extra host
    - name: create config for each extra host
      local_action:
        module: shell
        cmd: |
          mkdir -p "{{work_dir}}_orch"
          cd "{{work_dir}}_orch"
          mkdir -p "{{item.value.name}}"
          cd "{{item.value.name}}"

          echo "{{item.value.config_changes}}" | yq -P '.' > changes.yml 

          yq eval-all '. as $item ireduce ({}; . * $item)' {{playbook_dir}}/vars/nebula_default.reduced.yml changes.yml > config.yml

      loop: "{{hostvars | dict2items}}"
      loop_control:
        loop_var: item
      run_once: true
    
    # create tar for each host
    - name: create tar for each host
      local_action:
        module: shell
        cmd: |
          cd "{{work_dir}}_orch/{{item.value.name}}"

          tar zcvf out.tar --exclude "*.tar" *

      loop: "{{hostvars | dict2items}}"
      loop_control:
        loop_var: item
      run_once: true
    
    # create tar for each extra host
    - name: create tar for each extra host
      local_action:
        module: shell
        cmd: |
          cd "{{work_dir}}_orch/{{item.value.name}}"

          tar zcvf out.tar --exclude "*.tar" *

      loop: "{{other_hosts | dict2items}}"
      loop_control:
        loop_var: item
      run_once: true

    # create password file, if needed
    - name: create password file, if needed
      local_action:
        module: shell
        cmd: |
          dd if=/dev/urandom of={{item.value.local_password_file}} count=4 bs=1024
        creates: "{{item.value.local_password_file}}"
      loop: "{{hostvars | dict2items}}"
      loop_control:
        loop_var: item
      run_once: true

    # encrypt tar for each host
    - name: encrypt tar for each host
      local_action:
        module: shell
        cmd: |
          export pass_file={{item.value.local_password_file}}; 
          export in_file={{work_dir}}_orch/{{item.value.name}}/out.tar; 
          export enc_file={{work_dir}}_orch/{{item.value.name}}/out.tar.enc; 
          ~/playin/custom_bashrc/bin/enc_openssl encrypt | tee /tmp/enc.log # TODO make this not depend on the path like it is
      loop: "{{hostvars | dict2items}}"
      loop_control:
        loop_var: item
      run_once: true

    # encrypt tar for each extra host
    - name: encrypt tar for each extra host
      local_action:
        module: shell
        cmd: |
          export pass_file={{item.value.local_password_file}}; 
          export in_file={{work_dir}}_orch/{{item.value.name}}/out.tar; 
          export enc_file={{work_dir}}_orch/{{item.value.name}}/out.tar.enc; 
          ~/playin/custom_bashrc/bin/enc_openssl encrypt | tee /tmp/enc.log # TODO make this not depend on the path like it is
      loop: "{{other_hosts | dict2items}}"
      loop_control:
        loop_var: item
      run_once: true
    
    # copy password file to  hosts... prob want it to always mirror the one on the orch
    - name: copy password file to hosts
      copy: 
        backup: true
        dest: "/etc/nebula/password_file"
        src: "{{ hostvars[inventory_hostname].local_password_file }}"
        ansible_user: "{{hostvars[inventory_hostname].ansible_user}}"
      become: true

    - name: make sure nebula directory exists
      file: 
        path: /etc/nebula/inputfiles # use inputfiles to allow for more certs
        state: directory
      become: true

    # copy newly created .enc file to hosts
    - name: copy newly created .enc file to hosts
      copy: 
        backup: true
        dest: "/etc/nebula/out.tar.enc"
        src: "{{work_dir}}_orch/{{hostvars[inventory_hostname].name}}/out.tar.enc"
      become: true

    # decrypt the .enc file on the hosts
    - name: decrypt the .enc file on the hosts
      shell:
        cmd: |
          export pass_file="/etc/nebula/password_file";
          export enc_file=/etc/nebula/out.tar.enc; 
          export out_file=/tmp/out.tar; 
          ~/playin/custom_bashrc/bin/enc_openssl decrypt | tee /tmp/enc.log # TODO make this not depend on the path like it is

    # backup last added /etc/nebula/ca.crt
    - name: move files so network has some time to come up with new files
      copy: 
        backup: false
        dest: "/etc/nebula/inputfiles/ansible.{{ item }}.old"
        src: "/etc/nebula/inputfiles/ansible.{{ item }}.new"
        remote_src: true
      become: true
      ignore_errors: yes
      with_items: 
        - ca.crt

    # copy newly created crt and key to /etc/nebula/host.crt, /etc/nebula/host.key
    - name: copy client crt, key to clients
      copy: 
        backup: false
        dest: "/etc/nebula/{{ item }}"
        # src: "{{work_dir}}/{{hostvars[host].nebula_name}}/{{ item }}"
        src: "{{work_dir}}_orch/{{ hostvars[inventory_hostname].nebula_name }}/{{ item }}"
      become: true
      with_items: 
        - host.crt
        - host.key

    # copy newly created ca.crt to /etc/nebula/host.crt, /etc/nebula/host.key
    - name: copy ca.crt file to clients
      copy: 
        backup: false
        dest: "/etc/nebula/inputfiles/ansible.{{ item }}.new"
        # src: "{{work_dir}}/{{hostvars[host].nebula_name}}/{{ item }}"
        src: "{{work_dir}}_orch/{{ item }}"
      become: true
      with_items: 
        - ca.crt

    # TODO join the ca.cert into one file to be used by the config
    - name: join the ca.crt files to be used by the config
      shell:
        cmd: | 
          cd "{{nebula_config_client_folder}}"

          out_file="{{nebula_config_client_folder}}/{{item}}"

          printf "" > "$out_file" # clear the current file

          ls inputfiles | awk '/{{item}}/{print "cat inputfiles/" $1 " >> {{item}}"}' | bash

        executable: /bin/bash
      become: true 
      with_items:
        - ca.crt

    # copy to /etc/nebula/config.yml
    - name: copy client config file to clients
      copy: 
        backup: false
        dest: "/etc/nebula/{{ item }}"
        # src: "{{work_dir}}/{{hostvars[host].nebula_name}}/{{ item }}"
        src: "{{work_dir}}_orch/{{ hostvars[inventory_hostname].nebula_name }}/{{ item }}"
      become: true
      with_items: 
        - config.yml

    # create the systemd service 
    - name: create systemd service
      copy: 
        backup: false
        dest: "/etc/systemd/system/nebula.service"
        src: "nebula.service"
      become: true

    - name: start the nebula service 
      throttle: 1
      poll: 0
      async: 5
      systemd: 
        name: nebula
        state: restarted
        enabled: true
        no_block: yes
      become: true

- name: upload cert
  hosts: do.andbrant.com

  vars: 
    work_dir: /tmp/yeltnar-ansible

  tasks: 
    - name: "upload cert"
      copy:  
        backup: false
        dest: "~/playin/caddy-cloud/hot/ca.crt"
        src: "{{work_dir}}_orch/ca.crt"
