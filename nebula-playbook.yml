# TODO make sure jq, curl, openssl, yeltnar/custom_bashrc (for extract, enc_openssl) are installed installed
# TODO make sure Orch has yq, jq, curl, openssl, yeltnar/custom_bashrc (for extract, enc_openssl) are installed installed
# TODO make sure BECOME password is used 

# TODO don't use /tmp for files like nebula binaries and signing ca(?)

# TODO move 'extra hosts' into the hosts file, and use different name 
---
- name: testing cron
  tags:
  - never

  hosts: localhost

  tasks:  
    - name: Ensure a job that runs at 2 and 5 exists. Creates an entry like "0 5,2 * * ls -alh > /dev/null"
      become: true
      ansible.builtin.cron:
        name: "cron test"
        minute: "*"
        hour: "*"
        job: "date > /tmp/ansible-cron.txt"
        state: absent
        # state: present

    - meta: end_play


- name: set up encryption

  hosts: nebula_nodes
  any_errors_fatal: true

  vars: 
    work_dir: /tmp/yeltnar-ansible
    nebula_ca_name: "yeltnar nebula ca"
    nebula_config_client_folder: "/etc/nebula"
    var_dir: "/var/yeltnar-nebula"
    var_dir_orch: "/var/yeltnar-nebula_orch"
    # executable_dir # is found in vars/{os_type}/{processor_arch}

  vars_files:
    - vars/{{ansible_facts.system}}/{{ansible_facts.machine}}.yml
    - vars/orchestrator.yml # this needs to be changed to reflect the OS ansible is being ran on
    - vars/other_hosts.yml

  tags: 
    - setup-encryption

  tasks: 
    
    - name: make sure var directory exists on orch
      local_action:
        module: file 
        path: "{{var_dir_orch}}"
        state: directory
        owner: "1001" # these permissions are weird... they only work for one machine 
        group:  "1001" # these permissions are weird... they only work for one machine 
        # owner: "{{ hostvars[inventory_hostname].ansible_facts.user_uid }}"
        # group:  "{{ hostvars[inventory_hostname].ansible_facts.user_gid }}"
      become: true
      run_once: true
    
    - name: make sure var directory exists on hosts
      file:
        path: "{{var_dir}}"
        state: directory
        owner: "{{ hostvars[inventory_hostname].ansible_facts.user_uid }}"
        group:  "{{ hostvars[inventory_hostname].ansible_facts.user_gid }}"
      become: true

    # - name: delete old key
    #   file: 
    #     path: "{{var_dir}}/id_rsa"
    #     state: absent
    #   become: true
    
    - name: generate ssh keys 
      shell:
        cmd : |
          ssh-keygen -t rsa -m PEM -N "" -q -f "{{var_dir}}/id_rsa" -b 4096
          chmod 600 {{var_dir}}/id_rsa
          chmod 600 {{var_dir}}/id_rsa.pub
        creates: "{{var_dir}}/id_rsa"
   
    - name: download public rsa key from hosts to orchestrator 
      fetch: 
        flat: true
        # dest: "{{var_dir_orch}}/{{hostvars[inventory_hostname].name}}.pub"
        dest: "{{var_dir_orch}}/{{hostvars[inventory_hostname].name}}/"
        src: "{{var_dir}}/id_rsa.pub"
        fail_on_missing: true
    
    - name: fix downloaded pub key file permissions 
      local_action: 
        module: shell
        cmd: |
          PUBSSHKEY={{var_dir_orch}}/{{hostvars[inventory_hostname].name}}/id_rsa.pub
          chmod 600 $PUBSSHKEY
   
- name: set up encryption for other hosts

  hosts: nebula_nodes

  vars: 
    var_dir: "/var/yeltnar-nebula"
    var_dir_orch: "/var/yeltnar-nebula_orch"
  
  vars_files:
    # - vars/{{ansible_facts.system}}/{{ansible_facts.machine}}.yml
    # - vars/orchestrator.yml # this needs to be changed to reflect the OS ansible is being ran on
    - vars/other_hosts.yml

  tags:
  - setup-encryption

  tasks: 
    - name: generate ssh keys for other hosts
      local_action: 
        module: shell
        cmd : |
          echo {{var_dir_orch}}/{{item.value.name}}/id_rsa.pub does not exsist
          file {{var_dir_orch}}/{{item.value.name}}/id_rsa.pub
          ssh-keygen -t rsa -m PEM -N "" -q -f "{{var_dir_orch}}/{{item.value.name}}/id_rsa" -b 4096
          chmod 600 {{var_dir_orch}}/{{item.value.name}}/id_rsa
          chmod 600 {{var_dir_orch}}/{{item.value.name}}/id_rsa.pub
        creates: "{{var_dir_orch}}/{{item.value.name}}/id_rsa.pub"

      loop: "{{other_hosts | dict2items}}"
      loop_control:
        loop_var: item
      run_once: true

- name: set up orchestrator

  hosts: nebula_nodes
  any_errors_fatal: true
  order: reverse_inventory

  vars: 
    work_dir: /tmp/yeltnar-ansible
    nebula_ca_name: "yeltnar nebula ca"
    nebula_config_client_folder: "/etc/nebula"
    var_dir_orch: "/var/yeltnar-nebula_orch"
    # executable_dir # is found in vars/{os_type}/{processor_arch}

  vars_files:
    - vars/{{ansible_facts.system}}/{{ansible_facts.machine}}.yml
    - vars/orchestrator.yml # this needs to be changed to reflect the OS ansible is being ran on
    - vars/other_hosts.yml

  tasks:
    # - name: Print all available facts
    #   ansible.builtin.debug:
    #     var: ansible_facts

    # - name: write facts
    #   local_action:
    #     module: shell
    #   # shell:
    #   # sed -i s/4.20/4.x/ package.json
    #     # vars_files: 
    #     #   - vars/{{ansible_local.system}}/{{ansible_local.machine}}.yml
    
    # - name: Copy using inline content
    #   local_action:
    #     module: ansible.builtin.copy
    #     content: "{{hostvars}}"
    #     dest: /tmp/ansible.hosts.json
    #   run_once: true

    # - meta: end_play

    # install download binaries 
    - name: download binaries to orchestrator machine 
      local_action:
        module: shell
        executable: /bin/bash
        cmd: |
          version=$(curl https://api.github.com/repos/slackhq/nebula/releases/latest | jq -r .tag_name)
          
          mkdir -p "{{work_dir}}_orch"
          rm -rf {{work_dir}}_orch/*
          cd "{{work_dir}}_orch"
          
          curl -OL "https://github.com/slackhq/nebula/releases/download/$version/{{orchestrator_os_file_name}}"

          echo "$version\n{{orchestrator_os_file_name}}\n{{work_dir}}\n$PWD" > /tmp/drew_ansible.log

          PATH=$PATH:~/playin/custom_bashrc/bin

          whoami;
          pwd;

          extract {{orchestrator_os_file_name}}
        #creates: "/dev/nulll"
      run_once: true
      register: binaries_log

- name: create nebula files on orchestrator

  hosts: nebula_nodes
  any_errors_fatal: true
  order: reverse_inventory

  vars: 
    work_dir: /tmp/yeltnar-ansible
    nebula_ca_name: "yeltnar nebula ca"
    nebula_config_client_folder: "/etc/nebula"
    var_dir_orch: "/var/yeltnar-nebula_orch"
    var_dir: "/var/yeltnar-nebula"
    # executable_dir # is found in vars/{os_type}/{processor_arch}

  vars_files:
    - vars/{{ansible_facts.system}}/{{ansible_facts.machine}}.yml
    - vars/orchestrator.yml # this needs to be changed to reflect the OS ansible is being ran on
    - vars/other_hosts.yml

  tags:
  - minimal

  # TODO see about using tmpfs 
  tasks:

    # TODO maybe dont if it exists
    - name: create nebula ca 
      local_action:
        module: shell
        cmd: |
          cd "{{work_dir}}_orch"
          ./nebula-cert ca -name "{{nebula_ca_name}}"
        creates: "{{work_dir}}_orch/ca.crt"
      run_once: true

    # TODO as it sits now, this can not be run on its own
    - name: create nebula directories
      local_action:
        module: shell
        cmd: |
          cd "{{work_dir}}_orch"
          mkdir -p "{{item.value.name}}"
      loop: "{{hostvars | dict2items}}"
      run_once: true

    # TODO as it sits now, this can not be run on its own
    - name: create extra nebula devices directories 
      local_action:
        module: shell
        cmd: |
          cd "{{work_dir}}_orch"
          mkdir -p "{{item.value.name}}"
      loop: "{{other_hosts | dict2items}}"
      run_once: true

    - name: create nebula certs
      local_action:
        module: shell
        cmd: |
          cd "{{work_dir}}_orch"
          mkdir -p "{{item.value.name}}"

          ./nebula-cert sign \
          -out-crt {{item.value.name}}/host.crt -out-key {{item.value.name}}/host.key \
          -name "{{item.value.name}}" \
          -ip "{{item.value.nebula_ip}}" \
          -groups "{{item.value.signed_groups}}" 
      loop: "{{hostvars | dict2items}}"
      run_once: true

    - name: create nebula certs for extra devices
      local_action:
        module: shell
        cmd: |
          cd "{{work_dir}}_orch"
          mkdir -p "{{item.value.name}}"

          ./nebula-cert sign \
          -out-crt {{item.value.name}}/host.crt \
          -out-key {{item.value.name}}/host.key \
          -name "{{item.value.name}}" \
          -ip "{{item.value.nebula_ip}}" \
          -groups "{{item.value.signed_groups}}" 
      loop: "{{other_hosts | dict2items}}"
      run_once: true

    - name: copy ca.crt into device directory
      local_action:
        module: shell
        cmd: |
          cp "{{work_dir}}_orch/ca.crt" "{{work_dir}}_orch/{{item.value.name}}"
      loop: "{{hostvars | dict2items}}"
      run_once: true

    - name: copy ca.crt into extra devices' directory
      local_action:
        module: shell
        cmd: |
          cp "{{work_dir}}_orch/ca.crt" "{{work_dir}}_orch/{{item.value.name}}"
      loop: "{{other_hosts | dict2items}}"
      run_once: true
    
    # create the config.yml for each host
    - name: create config for hosts
      local_action:
        module: shell
        cmd: |
          mkdir -p "{{work_dir}}_orch"
          cd "{{work_dir}}_orch"
          mkdir -p "{{item.value.name}}"
          cd "{{item.value.name}}"

          echo "{{item.value.config_changes}}" | yq -P '.' > changes.yml 

          yq eval-all '. as $item ireduce ({}; . * $item)' {{playbook_dir}}/vars/nebula_default.reduced.yml changes.yml > config.yml

      loop: "{{hostvars | dict2items}}"
      loop_control:
        loop_var: item
      run_once: true
    
    # create the config.yml for each extra host
    - name: create config for each extra host
      local_action:
        module: shell
        cmd: |
          mkdir -p "{{work_dir}}_orch"
          cd "{{work_dir}}_orch"
          mkdir -p "{{item.value.name}}"
          cd "{{item.value.name}}"

          echo "{{item.value.config_changes}}" | yq -P '.' > changes.yml 

          yq eval-all '. as $item ireduce ({}; . * $item)' {{playbook_dir}}/vars/nebula_default.reduced.yml changes.yml > config.yml

      loop: "{{hostvars | dict2items}}"
      loop_control:
        loop_var: item
      run_once: true
    
    # create tar for each host
    - name: create tar for each host
      local_action:
        module: shell
        cmd: |
          cd "{{work_dir}}_orch/{{item.value.name}}"

          tar zcvf out.tar --exclude "*.tar" *

      loop: "{{hostvars | dict2items}}"
      loop_control:
        loop_var: item
      run_once: true
    
    # create tar for each extra host
    - name: create tar for each extra host
      local_action:
        module: shell
        cmd: |
          cd "{{work_dir}}_orch/{{item.value.name}}"

          tar zcvf out.tar --exclude "*.tar" *

      loop: "{{other_hosts | dict2items}}"
      loop_control:
        loop_var: item
      run_once: true

    - name: encrypt with public rsa key for hosts
      local_action: 
        module: shell
        cmd: |

          export workdir="{{var_dir}}/workdir"
          export FILE_TO_ENCRYPT={{work_dir}}_orch/{{item.value.name}}/out.tar;
          export ENCRYPTED_FILE={{work_dir}}_orch/{{item.value.name}}/out.tar.enc; 
          export PUB_KEY={{item.value.public_key_location}}
          export AES_KEY_ENC={{work_dir}}_orch/{{item.value.name}}/out.pass.enc; 

          if [ ! -e $PUB_KEY ]; then
            exit -1
          fi

          mkdir -p "$workdir"
          
          $HOME/playin/custom_bashrc/bin/rsa_enc encrypt

      loop: "{{hostvars | dict2items}}"
      loop_control:
        loop_var: item
      run_once: true

    - name: encrypt with public rsa key for other hosts
      local_action: 
        module: shell
        cmd: |

          export workdir="{{var_dir}}/workdir"
          export FILE_TO_ENCRYPT={{work_dir}}_orch/{{item.value.name}}/out.tar;
          export ENCRYPTED_FILE={{work_dir}}_orch/{{item.value.name}}/out.tar.enc; 
          export PUB_KEY={{item.value.public_key_location}}
          export AES_KEY_ENC={{work_dir}}_orch/{{item.value.name}}/out.pass.enc; 

          if [ ! -e $PUB_KEY ]; then
            exit -1
          fi
          
          $HOME/playin/custom_bashrc/bin/rsa_enc encrypt

      loop: "{{other_hosts | dict2items}}"
      loop_control:
        loop_var: item
      run_once: true
    
- name: setup hosts

  hosts: nebula_nodes
  any_errors_fatal: true

  vars: 
    work_dir: /tmp/yeltnar-ansible
    nebula_ca_name: "yeltnar nebula ca"
    nebula_config_client_folder: "/etc/nebula"
    var_dir: "/var/yeltnar-nebula"
    var_dir_orch: "/var/yeltnar-nebula_orch"

  vars_files:
    - vars/{{ansible_facts.system}}/{{ansible_facts.machine}}.yml
    - vars/orchestrator.yml # this needs to be changed to reflect the OS ansible is being ran on
    - vars/other_hosts.yml

  tasks: 
    # download binaries to client machines 
    - name: download binaries to client machines
      shell:
        executable: /bin/bash
        cmd: |

          version=$(curl https://api.github.com/repos/slackhq/nebula/releases/latest | jq -r .tag_name)
          
          mkdir -p {{work_dir}}
          rm -rf {{work_dir}}/*
          cd {{work_dir}}
          
          curl -OL "https://github.com/slackhq/nebula/releases/download/$version/{{os_file_name}}"

          ~/playin/custom_bashrc/bin/extract {{os_file_name}} # TODO need to be more dynamic

    - name: move binaries to bin dir (as root)
      shell:
        cmd : |
          cd {{work_dir}}
          mv nebula {{executable_dir}}/
          mv nebula-cert {{executable_dir}}/
          cd .. && rm -rf {{work_dir}}
      become: true
   
    - name: make sure nebula directory exists
      file: 
        path: "{{nebula_config_client_folder}}/inputfiles" # use inputfiles to allow for more certs
        state: directory
        owner: "{{ hostvars[inventory_hostname].ansible_facts.user_uid }}"
        group:  "{{ hostvars[inventory_hostname].ansible_facts.user_gid }}"
      become: true
    
    - name: make sure tar_stuff directory exists
      file: 
        path: "{{var_dir}}/tar_stuff/"
        state: directory
        owner: "{{ hostvars[inventory_hostname].ansible_facts.user_uid }}"
        group:  "{{ hostvars[inventory_hostname].ansible_facts.user_gid }}"
      become: true

- name: upload .enc to server (currently private network) for later downloading 
  
  hosts: 10.10.10.8
  # any_errors_fatal: true

  vars: 
    work_dir: /tmp/yeltnar-ansible
    nebula_ca_name: "yeltnar nebula ca"
    nebula_config_client_folder: "/etc/nebula"
    var_dir: "/var/yeltnar-nebula"
    var_dir_orch: "/var/yeltnar-nebula_orch"
    # executable_dir # is found in vars/{os_type}/{processor_arch}

  vars_files:
    - vars/{{ansible_facts.system}}/{{ansible_facts.machine}}.yml
    - vars/orchestrator.yml # this needs to be changed to reflect the OS ansible is being ran on
    - vars/other_hosts.yml

  tags:
  - minimal
  - upload

  tasks: 

    - name: make sure hot nebula directory exists
      file: 
        path: "{{ hostvars[inventory_hostname].ansible_facts.user_dir }}/playin/caddy/hot/nebula"
        state: directory
        owner: "{{ hostvars[inventory_hostname].ansible_facts.user_uid }}"
        group:  "{{ hostvars[inventory_hostname].ansible_facts.user_gid }}"

    - name: "upload hosts config.enc files to hosting server"
      copy:
        backup: false
        dest: "{{ hostvars[inventory_hostname].ansible_facts.user_dir }}/playin/caddy/hot/nebula/{{item.value.name}}.tar.enc"
        src: "{{work_dir}}_orch/{{item.value.name}}/out.tar.enc"
      loop: "{{hostvars | dict2items}}"
      run_once: true

    - name: "upload extra hosts config.enc files to hosting server"
      copy:
        backup: false
        dest: "{{ hostvars[inventory_hostname].ansible_facts.user_dir }}/playin/caddy/hot/nebula/{{item.value.name}}.tar.enc"
        src: "{{work_dir}}_orch/{{item.value.name}}/out.tar.enc"
      loop: "{{other_hosts | dict2items}}"
      run_once: true

    - name: "upload hosts pass.enc files to hosting server"
      copy:
        backup: false
        dest: "{{ hostvars[inventory_hostname].ansible_facts.user_dir }}/playin/caddy/hot/nebula/{{item.value.name}}.pass.enc"
        src: "{{work_dir}}_orch/{{item.value.name}}/out.pass.enc"
      loop: "{{hostvars | dict2items}}"
      run_once: true

    - name: "upload extra hosts pass.enc files to hosting server"
      copy:
        backup: false
        dest: "{{ hostvars[inventory_hostname].ansible_facts.user_dir }}/playin/caddy/hot/nebula/{{item.value.name}}.pass.enc"
        src: "{{work_dir}}_orch/{{item.value.name}}/out.pass.enc"
      loop: "{{other_hosts | dict2items}}"
      run_once: true

    - name: "upload ca.crt public file"
      copy:
        backup: false
        dest: "{{ hostvars[inventory_hostname].ansible_facts.user_dir }}/playin/caddy/hot/nebula/"
        src: "{{work_dir}}_orch/ca.crt"
      run_once: true

    - name: "create file which has last updated time"
      copy:
        backup: false
        dest: "{{ hostvars[inventory_hostname].ansible_facts.user_dir }}/playin/caddy/hot/nebula/{{item.value.name}}.date"
        content: "{{ ansible_date_time.epoch }}"
      loop: "{{hostvars | dict2items}}"
      run_once: true

    - name: "create file which has last updated time for other hosts"
      copy:
        backup: false
        dest: "{{ hostvars[inventory_hostname].ansible_facts.user_dir }}/playin/caddy/hot/nebula/{{item.value.name}}.date"
        content: "{{ ansible_date_time.epoch }}"
      loop: "{{other_hosts | dict2items}}"
      run_once: true

# TODO change this to be based on downloading... if we don't have the most up to date version 
- name: copy password and enc files to hosts

  hosts: nebula_nodes
  any_errors_fatal: true

  vars: 
    work_dir: /tmp/yeltnar-ansible
    nebula_ca_name: "yeltnar nebula ca"
    nebula_config_client_folder: "/etc/nebula"
    var_dir: "/var/yeltnar-nebula"
    var_dir_orch: "/var/yeltnar-nebula_orch"
    # executable_dir # is found in vars/{os_type}/{processor_arch}

  vars_files:
    - vars/{{ansible_facts.system}}/{{ansible_facts.machine}}.yml
    - vars/orchestrator.yml # this needs to be changed to reflect the OS ansible is being ran on
    - vars/other_hosts.yml

  tags:
  - minimal

  tasks:

    - name: make sure /tmp/nebula directory exists
      file: 
        path: "{{var_dir}}/tar_stuff/"
        state: directory
        owner: "{{ hostvars[inventory_hostname].ansible_facts.user_uid }}"
        group:  "{{ hostvars[inventory_hostname].ansible_facts.user_gid }}"
      become: true   
    
    # TODO WARNING: this depends on communication between the two machines... we want to avoid this
    - name: upload config.enc file 
      copy: 
        src: "{{work_dir}}_orch/{{hostvars[inventory_hostname].name}}/out.tar.enc"
        dest: "{{var_dir}}/tar_stuff/out.tar.enc"
        # backup: true
    
    # TODO WARNING: this depends on communication between the two machines... we want to avoid this
    - name: upload password.enc file 
      copy: 
        src: "{{work_dir}}_orch/{{hostvars[inventory_hostname].name}}/out.pass.enc"
        dest: "{{var_dir}}/tar_stuff/out.pass.enc"
        # backup: true

- name: check for new and setup hosts' new config files

  hosts: nebula_nodes
  any_errors_fatal: true
  order: reverse_inventory

  tags:
    - for-host
    - minimal

  vars: 
    nebula_config_client_folder: "/etc/nebula"
    var_dir: "/var/yeltnar-nebula"

  tasks: 
  
    - name: "upload script which updates nebula files"
      copy:
        dest: "{{ var_dir }}/process_tar.sh"
        src: "{{ playbook_dir }}/process_tar.sh"
        mode: '500'
      # loop: "{{hostvars | dict2items}}"
      # run_once: true
  
    - name: "upload script which checks server for new nebula files"
      copy:
        dest: "{{ var_dir }}/compare_date.sh"
        src: "{{ playbook_dir }}/compare_date.sh"
        mode: '500'
      # loop: "{{hostvars | dict2items}}"
      # run_once: true
  
    - name: "upload cert for private network"
      copy:
        dest: "{{ var_dir }}/knownca.pem"
        src: "knownca.pem"
        mode: '500'
      # loop: "{{hostvars | dict2items}}"
      # run_once: true
  
    - name: "create .env file for scripts"
      copy:
        dest: "{{ var_dir }}/.env"
        content: |
          export HOST="{{ hostvars[inventory_hostname].update_daemon.HOST }}"
          export PORT="{{ hostvars[inventory_hostname].update_daemon.PORT }}"
          export SECONDARY_HOST="{{ hostvars[inventory_hostname].update_daemon.SECONDARY_HOST }}"
          export SECONDARY_PORT="{{ hostvars[inventory_hostname].update_daemon.SECONDARY_PORT }}"
          export DEVICE_NAME="{{ hostvars[inventory_hostname].name }}"
          export DATE_FILE_PATH="{{var_dir}}/tar_stuff/remote_updated.date"
          export var_dir="{{var_dir}}"
          export nebula_config_client_folder="{{nebula_config_client_folder}}"
          export CURL_OPTIONS="--cacert ./knownca.pem"
        mode: '400'
      # loop: "{{hostvars | dict2items}}"
      # run_once: true

    # - meta: end_play

    # TODO change to 'check for update' script; this would also be run with sudo chron
    # - name: run script to dec, extract, move to correct location 
    #   shell: 
    #     cmd: |
    #       cd {{ var_dir }}
    #       touch {{ var_dir }}/compare_date.log; 
    #       chown {{ hostvars[inventory_hostname].ansible_facts.user_uid }}:{{ hostvars[inventory_hostname].ansible_facts.user_gid }} {{ var_dir }}/compare_date.log
    #       {{ var_dir }}/compare_date.sh 2>&1 | tee {{ var_dir }}/compare_date.log
    #   become: true

- name: create the systemd service 

  hosts: nebula_nodes
  any_errors_fatal: true
  order: reverse_inventory

  vars: 
    work_dir: /tmp/yeltnar-ansible
    nebula_ca_name: "yeltnar nebula ca"
    nebula_config_client_folder: "/etc/nebula"
    var_dir: "/var/yeltnar-nebula"
    var_dir_orch: "/var/yeltnar-nebula_orch"
    # executable_dir # is found in vars/{os_type}/{processor_arch}

  vars_files:
    - vars/{{ansible_facts.system}}/{{ansible_facts.machine}}.yml
    - vars/orchestrator.yml # this needs to be changed to reflect the OS ansible is being ran on
    - vars/other_hosts.yml

  tags:
    - minimal

  tasks: 

    # - meta: end_play

    # TODO WARNING This is a copy command that depends on localhost having it
    - name: create systemd service
      copy: 
        backup: false
        dest: "/etc/systemd/system/nebula.service"
        src: "nebula.service"
      become: true

    - name: start the nebula service 
      throttle: 1
      poll: 0
      async: 5
      systemd: 
        name: nebula
        state: restarted
        enabled: true
        no_block: yes
      become: true

