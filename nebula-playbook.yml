# TODO make sure jq, curl, openssl, yeltnar/custom_bashrc (for extract, enc_openssl) are installed installed
# TODO make sure Orch has yq, jq, curl, openssl, yeltnar/custom_bashrc (for extract, enc_openssl) are installed installed
# TODO make sure BECOME password is used 

---
- name: set up encryption

  hosts: nebula_nodes
  any_errors_fatal: true

  vars: 
    work_dir: /tmp/yeltnar-ansible
    nebula_ca_name: "yeltnar nebula ca"
    nebula_config_client_folder: "/etc/nebula"
    var_dir: "/var/yeltnar-nebula"
    var_dir_orch: "/var/yeltnar-nebula_orch"
    # executable_dir # is found in vars/{os_type}/{processor_arch}

  vars_files:
    - vars/{{ansible_facts.system}}/{{ansible_facts.machine}}.yml
    - vars/orchestrator.yml # this needs to be changed to reflect the OS ansible is being ran on
    - vars/other_hosts.yml

  tasks: 
    
    - name: make sure var directory exists on orch
      local_action:
        module: file 
        path: "{{var_dir_orch}}"
        state: directory
        owner: "1001" # these permissions are weird... they only work for one machine 
        group:  "1001" # these permissions are weird... they only work for one machine 
        # owner: "{{ hostvars[inventory_hostname].ansible_facts.user_uid }}"
        # group:  "{{ hostvars[inventory_hostname].ansible_facts.user_gid }}"
      become: true
      run_once: true
    
    - name: make sure var directory exists on hosts
      file:
        path: "{{var_dir}}"
        state: directory
        owner: "{{ hostvars[inventory_hostname].ansible_facts.user_uid }}"
        group:  "{{ hostvars[inventory_hostname].ansible_facts.user_gid }}"
      become: true
    
    - name: generate ssh keys 
      shell:
        cmd : |
          ssh-keygen -m PEM -N '' -q -f {{var_dir}}/id_rsa
          chmod 600 {{var_dir}}/id_rsa
          chmod 600 {{var_dir}}/id_rsa.pub
        creates: "{{var_dir}}/id_rsa"
   
    - name: download public rsa key 
      fetch: 
        flat: true
        # dest: "{{var_dir_orch}}/{{hostvars[inventory_hostname].name}}.pub"
        dest: "{{var_dir_orch}}/{{hostvars[inventory_hostname].name}}/"
        src: "{{var_dir}}/id_rsa.pub"
        fail_on_missing: true
    
    - name: fix downloaded pub key file permissions 
      local_action: 
        module: shell
        cmd: |
          PUBSSHKEY={{var_dir_orch}}/{{hostvars[inventory_hostname].name}}/id_rsa.pub
          chmod 600 $PUBSSHKEY
   
- name: set up orchestrator

  hosts: nebula_nodes
  any_errors_fatal: true
  order: reverse_inventory

  vars: 
    work_dir: /tmp/yeltnar-ansible
    nebula_ca_name: "yeltnar nebula ca"
    nebula_config_client_folder: "/etc/nebula"
    var_dir_orch: "/var/yeltnar-nebula_orch"
    # executable_dir # is found in vars/{os_type}/{processor_arch}

  vars_files:
    - vars/{{ansible_facts.system}}/{{ansible_facts.machine}}.yml
    - vars/orchestrator.yml # this needs to be changed to reflect the OS ansible is being ran on
    - vars/other_hosts.yml

  tasks:
    # - name: Print all available facts
    #   ansible.builtin.debug:
    #     var: ansible_facts

    # - name: write facts
    #   local_action:
    #     module: shell
    #   # shell:
    #   # sed -i s/4.20/4.x/ package.json
    #     # vars_files: 
    #     #   - vars/{{ansible_local.system}}/{{ansible_local.machine}}.yml
    
    # - name: Copy using inline content
    #   local_action:
    #     module: ansible.builtin.copy
    #     content: "{{hostvars}}"
    #     dest: /tmp/ansible.hosts.json
    #   run_once: true

    # - meta: end_play

    # install download binaries 
    - name: download binaries to orchestrator machine 
      local_action:
        module: shell
        executable: /bin/bash
        cmd: |
          version=$(curl https://api.github.com/repos/slackhq/nebula/releases/latest | jq -r .tag_name)
          
          mkdir -p "{{work_dir}}_orch"
          rm -rf {{work_dir}}_orch/*
          cd "{{work_dir}}_orch"
          
          curl -OL "https://github.com/slackhq/nebula/releases/download/$version/{{orchestrator_os_file_name}}"

          echo "$version\n{{orchestrator_os_file_name}}\n{{work_dir}}\n$PWD" > /tmp/drew_ansible.log

          PATH=$PATH:~/playin/custom_bashrc/bin

          whoami;
          pwd;

          extract {{orchestrator_os_file_name}}
        #creates: "/dev/nulll"
      run_once: true
      register: binaries_log

    # TODO maybe dont if it exists
    - name: create nebula ca 
      local_action:
        module: shell
        cmd: |
          cd "{{work_dir}}_orch"
          ./nebula-cert ca -name "{{nebula_ca_name}}"
        creates: "{{work_dir}}/ca.crt"
      run_once: true

    - name: create nebula directories
      local_action:
        module: shell
        cmd: |
          cd "{{work_dir}}_orch"
          mkdir -p "{{item.value.name}}"
      loop: "{{hostvars | dict2items}}"
      run_once: true

    - name: create extra nebula devices directories 
      local_action:
        module: shell
        cmd: |
          cd "{{work_dir}}_orch"
          mkdir -p "{{item.value.name}}"
      loop: "{{other_hosts | dict2items}}"
      run_once: true

    - name: create nebula certs
      local_action:
        module: shell
        cmd: |
          cd "{{work_dir}}_orch"
          mkdir -p "{{item.value.name}}"

          ./nebula-cert sign \
          -out-crt {{item.value.name}}/host.crt -out-key {{item.value.name}}/host.key \
          -name "{{item.value.name}}" \
          -ip "{{item.value.nebula_ip}}" \
          -groups "{{item.value.signed_groups}}" 
      loop: "{{hostvars | dict2items}}"
      run_once: true

    - name: create nebula certs for extra devices
      local_action:
        module: shell
        cmd: |
          cd "{{work_dir}}_orch"
          mkdir -p "{{item.value.name}}"

          ./nebula-cert sign \
          -out-crt {{item.value.name}}/host.crt \
          -out-key {{item.value.name}}/host.key \
          -name "{{item.value.name}}" \
          -ip "{{item.value.nebula_ip}}" \
          -groups "{{item.value.signed_groups}}" 
      loop: "{{other_hosts | dict2items}}"
      run_once: true

    - name: copy ca.crt into device directory
      local_action:
        module: shell
        cmd: |
          cp "{{work_dir}}_orch/ca.crt" "{{work_dir}}_orch/{{item.value.name}}"
      loop: "{{hostvars | dict2items}}"
      run_once: true

    - name: copy ca.crt into extra devices' directory
      local_action:
        module: shell
        cmd: |
          cp "{{work_dir}}_orch/ca.crt" "{{work_dir}}_orch/{{item.value.name}}"
      loop: "{{other_hosts | dict2items}}"
      run_once: true
    
    # create the config.yml for each host
    - name: create config for hosts
      local_action:
        module: shell
        cmd: |
          mkdir -p "{{work_dir}}_orch"
          cd "{{work_dir}}_orch"
          mkdir -p "{{item.value.name}}"
          cd "{{item.value.name}}"

          echo "{{item.value.config_changes}}" | yq -P '.' > changes.yml 

          yq eval-all '. as $item ireduce ({}; . * $item)' {{playbook_dir}}/vars/nebula_default.reduced.yml changes.yml > config.yml

      loop: "{{hostvars | dict2items}}"
      loop_control:
        loop_var: item
      run_once: true
    
    # create the config.yml for each extra host
    - name: create config for each extra host
      local_action:
        module: shell
        cmd: |
          mkdir -p "{{work_dir}}_orch"
          cd "{{work_dir}}_orch"
          mkdir -p "{{item.value.name}}"
          cd "{{item.value.name}}"

          echo "{{item.value.config_changes}}" | yq -P '.' > changes.yml 

          yq eval-all '. as $item ireduce ({}; . * $item)' {{playbook_dir}}/vars/nebula_default.reduced.yml changes.yml > config.yml

      loop: "{{hostvars | dict2items}}"
      loop_control:
        loop_var: item
      run_once: true
    
    # create tar for each host
    - name: create tar for each host
      local_action:
        module: shell
        cmd: |
          cd "{{work_dir}}_orch/{{item.value.name}}"

          tar zcvf out.tar --exclude "*.tar" *

      loop: "{{hostvars | dict2items}}"
      loop_control:
        loop_var: item
      run_once: true
    
    # create tar for each extra host
    - name: create tar for each extra host
      local_action:
        module: shell
        cmd: |
          cd "{{work_dir}}_orch/{{item.value.name}}"

          tar zcvf out.tar --exclude "*.tar" *

      loop: "{{other_hosts | dict2items}}"
      loop_control:
        loop_var: item
      run_once: true

    - name: encrypt with public rsa key for hosts
      local_action: 
        module: shell
        cmd: |
          cd {{work_dir}}_orch/{{item.value.name}}

          PUBSSHKEY={{item.value.public_key_location}}
          PUBKEY={{var_dir_orch}}/{{item.value.name}}.pkcs8
          FILE_TO_ENCRYPT={{work_dir}}_orch/{{item.value.name}}/out.tar;
          ENCRYPTED_FILE={{work_dir}}_orch/{{item.value.name}}/out.tar.enc; 
          ENCRYPTED_FILE_PASSWORD={{work_dir}}_orch/{{item.value.name}}/out.pass.enc; 

          if [ ! -e $PUBSSHKEY ]; then
            exit -1
          fi

          openssl rand -out secret.key 32
          openssl enc -aes-256-cbc -e -pbkdf2 -pass file:secret.key -a -iter 100000 -salt -in "${FILE_TO_ENCRYPT}" -out "${ENCRYPTED_FILE}" 
          
          ssh-keygen -e -f "${PUBSSHKEY}" -m PKCS8 > "${PUBKEY}"
          openssl pkeyutl -encrypt -pubin -inkey "${PUBKEY}" -in "secret.key" -out "${ENCRYPTED_FILE_PASSWORD}" 2>&1 | tee /tmp/{{item.value.name}}.enc.log

          rm secret.key # delete rsa secret

      loop: "{{hostvars | dict2items}}"
      loop_control:
        loop_var: item
      run_once: true

    - name: encrypt with public rsa key for other hosts
      local_action: 
        module: shell
        cmd: |
          cd {{work_dir}}_orch/{{item.value.name}}

          PUBSSHKEY={{item.value.public_key_location}}
          PUBKEY={{var_dir_orch}}/{{item.value.name}}.pkcs8
          FILE_TO_ENCRYPT={{work_dir}}_orch/{{item.value.name}}/out.tar;
          ENCRYPTED_FILE={{work_dir}}_orch/{{item.value.name}}/out.tar.enc; 
          ENCRYPTED_FILE_PASSWORD={{work_dir}}_orch/{{item.value.name}}/out.pass.enc; 

          if [ ! -e $PUBSSHKEY ]; then
            exit -1
          fi

          openssl rand -out secret.key 32
          openssl enc -aes-256-cbc -e -pbkdf2 -pass file:secret.key -a -iter 100000 -salt -in "${FILE_TO_ENCRYPT}" -out "${ENCRYPTED_FILE}" 
          
          ssh-keygen -e -f "${PUBSSHKEY}" -m PKCS8 > "${PUBKEY}"
          openssl pkeyutl -encrypt -pubin -inkey "${PUBKEY}" -in "secret.key" -out "${ENCRYPTED_FILE_PASSWORD}" 2>&1 | tee /tmp/{{item.value.name}}.enc.log

          rm secret.key # delete rsa secret

      loop: "{{other_hosts | dict2items}}"
      loop_control:
        loop_var: item
      run_once: true
    
- name: setup hosts

  hosts: nebula_nodes
  any_errors_fatal: true

  vars: 
    work_dir: /tmp/yeltnar-ansible
    nebula_ca_name: "yeltnar nebula ca"
    nebula_config_client_folder: "/etc/nebula"
    var_dir: "/var/yeltnar-nebula"
    var_dir_orch: "/var/yeltnar-nebula_orch"

  vars_files:
    - vars/{{ansible_facts.system}}/{{ansible_facts.machine}}.yml
    - vars/orchestrator.yml # this needs to be changed to reflect the OS ansible is being ran on
    - vars/other_hosts.yml

  tasks: 
    # download binaries to client machines 
    - name: download binaries to client machines
      shell:
        executable: /bin/bash
        cmd: |

          version=$(curl https://api.github.com/repos/slackhq/nebula/releases/latest | jq -r .tag_name)
          
          mkdir -p {{work_dir}}
          rm -rf {{work_dir}}/*
          cd {{work_dir}}
          
          curl -OL "https://github.com/slackhq/nebula/releases/download/$version/{{os_file_name}}"

          ~/playin/custom_bashrc/bin/extract {{os_file_name}} # TODO need to be more dynamic

    - name: move binaries to bin dir (as root)
      shell:
        cmd : |
          cd {{work_dir}}
          mv nebula {{executable_dir}}/
          mv nebula-cert {{executable_dir}}/
          cd .. && rm -rf {{work_dir}}
      become: true
   
    - name: make sure nebula directory exists
      file: 
        path: "{{nebula_config_client_folder}}/inputfiles" # use inputfiles to allow for more certs
        state: directory
        owner: "{{ hostvars[inventory_hostname].ansible_facts.user_uid }}"
        group:  "{{ hostvars[inventory_hostname].ansible_facts.user_gid }}"
      become: true
    
    - name: make sure tar_stuff directory exists
      file: 
        path: "{{var_dir}}/tar_stuff/"
        state: directory
        owner: "{{ hostvars[inventory_hostname].ansible_facts.user_uid }}"
        group:  "{{ hostvars[inventory_hostname].ansible_facts.user_gid }}"
      become: true

- name: upload .enc to server (currently private network) for later downloading 
  
  hosts: 10.10.10.8
  # any_errors_fatal: true

  vars: 
    work_dir: /tmp/yeltnar-ansible
    nebula_ca_name: "yeltnar nebula ca"
    nebula_config_client_folder: "/etc/nebula"
    var_dir: "/var/yeltnar-nebula"
    var_dir_orch: "/var/yeltnar-nebula_orch"
    # executable_dir # is found in vars/{os_type}/{processor_arch}

  vars_files:
    - vars/{{ansible_facts.system}}/{{ansible_facts.machine}}.yml
    - vars/orchestrator.yml # this needs to be changed to reflect the OS ansible is being ran on
    - vars/other_hosts.yml

  tasks: 

    - name: make sure hot nebula directory exists
      file: 
        path: "{{ hostvars[inventory_hostname].ansible_facts.user_dir }}/playin/caddy/hot/nebula"
        state: directory
        owner: "{{ hostvars[inventory_hostname].ansible_facts.user_uid }}"
        group:  "{{ hostvars[inventory_hostname].ansible_facts.user_gid }}"

    - name: "upload hosts config.enc files to hosting server"
      copy:
        backup: false
        dest: "{{ hostvars[inventory_hostname].ansible_facts.user_dir }}/playin/caddy/hot/nebula/{{item.value.name}}.tar.enc"
        src: "{{work_dir}}_orch/{{item.value.name}}/out.tar.enc"
      loop: "{{hostvars | dict2items}}"
      run_once: true

    - name: "upload extra hosts config.enc files to hosting server"
      copy:
        backup: false
        dest: "{{ hostvars[inventory_hostname].ansible_facts.user_dir }}/playin/caddy/hot/nebula/{{item.value.name}}.tar.enc"
        src: "{{work_dir}}_orch/{{item.value.name}}/out.tar.enc"
      loop: "{{other_hosts | dict2items}}"
      run_once: true

    - name: "upload hosts pass.enc files to hosting server"
      copy:
        backup: false
        dest: "{{ hostvars[inventory_hostname].ansible_facts.user_dir }}/playin/caddy/hot/nebula/{{item.value.name}}.pass.enc"
        src: "{{work_dir}}_orch/{{item.value.name}}/out.pass.enc"
      loop: "{{hostvars | dict2items}}"
      run_once: true

    - name: "upload extra hosts pass.enc files to hosting server"
      copy:
        backup: false
        dest: "{{ hostvars[inventory_hostname].ansible_facts.user_dir }}/playin/caddy/hot/nebula/{{item.value.name}}.pass.enc"
        src: "{{work_dir}}_orch/{{item.value.name}}/out.pass.enc"
      loop: "{{other_hosts | dict2items}}"
      run_once: true

# TODO change this to be based on downloading... if we don't have the most up to date version 
- name: copy password and enc files to hosts

  hosts: nebula_nodes
  any_errors_fatal: true

  vars: 
    work_dir: /tmp/yeltnar-ansible
    nebula_ca_name: "yeltnar nebula ca"
    nebula_config_client_folder: "/etc/nebula"
    var_dir: "/var/yeltnar-nebula"
    var_dir_orch: "/var/yeltnar-nebula_orch"
    # executable_dir # is found in vars/{os_type}/{processor_arch}

  vars_files:
    - vars/{{ansible_facts.system}}/{{ansible_facts.machine}}.yml
    - vars/orchestrator.yml # this needs to be changed to reflect the OS ansible is being ran on
    - vars/other_hosts.yml

  tasks:

    - name: make sure /tmp/nebula directory exists
      file: 
        path: "{{var_dir}}/tar_stuff/"
        state: directory
        owner: "{{ hostvars[inventory_hostname].ansible_facts.user_uid }}"
        group:  "{{ hostvars[inventory_hostname].ansible_facts.user_gid }}"
      become: true   
    
    # TODO WARNING: this depends on communication between the two machines... we want to avoid this
    - name: upload config.enc file 
      copy: 
        src: "{{work_dir}}_orch/{{hostvars[inventory_hostname].name}}/out.tar.enc"
        dest: "{{var_dir}}/tar_stuff/out.tar.enc"
        # backup: true
    
    # TODO WARNING: this depends on communication between the two machines... we want to avoid this
    - name: upload password.enc file 
      copy: 
        src: "{{work_dir}}_orch/{{hostvars[inventory_hostname].name}}/out.pass.enc"
        dest: "{{var_dir}}/tar_stuff/out.pass.enc"
        # backup: true

- name: setup hosts new config files

  hosts: nebula_nodes
  any_errors_fatal: true
  order: reverse_inventory

  tags:
    - for-host

  vars: 
    nebula_config_client_folder: "/etc/nebula"
    var_dir: "/var/yeltnar-nebula"

  tasks: 

    - name: decrypt with private rsa key
      shell: 
        cmd: |
          mkdir -p {{var_dir}}/workdir # this will fail if var_dir is not there 
          cd {{var_dir}}/workdir

          PRIVKEY={{var_dir}}/id_rsa          
          ENCRYPTED_FILE_PASSWORD={{var_dir}}/tar_stuff/out.pass.enc;

          ENCRYPTED_FILE={{var_dir}}/tar_stuff/out.tar.enc;
          DECRYPTED_FILE={{var_dir}}/tar_stuff/out.tar; 

          openssl pkeyutl -decrypt -inkey "${PRIVKEY}" -in "${ENCRYPTED_FILE_PASSWORD}" -out "secret.key"
          
          openssl enc -aes-256-cbc -d -pbkdf2 -pass file:secret.key -a -iter 100000 -salt -in "${ENCRYPTED_FILE}" -out "${DECRYPTED_FILE}" 

    - name: extract the tar
      shell:
        cmd: |
          cd {{var_dir}}/tar_stuff/
          {{ hostvars[inventory_hostname].ansible_facts.user_dir }}/playin/custom_bashrc/bin/extract out.tar

          chown "{{ hostvars[inventory_hostname].ansible_facts.user_uid }}":"{{ hostvars[inventory_hostname].ansible_facts.user_gid }}" * 
          
    # backup last added ca.crt
    - name: move files so network has some time to come up with new files
      copy: 
        backup: false
        dest: "{{nebula_config_client_folder}}/inputfiles/ansible.{{ item }}.old"
        src: "{{nebula_config_client_folder}}/inputfiles/ansible.{{ item }}.new"
        remote_src: true
      become: true
      ignore_errors: yes
      with_items: 
        - ca.crt

    - name: copy newly created crt, key, and config.yml to nebula directory 
      copy: 
        backup: false
        dest: "{{nebula_config_client_folder}}/{{ item }}"
        src: "{{var_dir}}/tar_stuff/{{ item }}"
        remote_src: true
      become: true
      with_items: 
        - host.crt
        - host.key
        - config.yml

    - name: copy ca.crt file to nebula dir
      copy: 
        backup: false
        dest: "{{nebula_config_client_folder}}/inputfiles/ansible.{{ item }}.new"
        src: "{{var_dir}}/tar_stuff/{{ item }}"
        remote_src: true
      become: true
      with_items: 
        - ca.crt

    - name: join the ca.crt files to be used by the config
      shell:
        cmd: | 
          cd "{{nebula_config_client_folder}}"

          out_file="{{nebula_config_client_folder}}/{{item}}"

          printf "" > "$out_file" # clear the current file

          ls inputfiles | awk '/{{item}}/{print "cat inputfiles/" $1 " >> {{item}}"}' | bash

        executable: /bin/bash
      become: true 
      with_items:
        - ca.crt

- name: create the systemd service 

  hosts: nebula_nodes
  any_errors_fatal: true
  order: reverse_inventory

  vars: 
    work_dir: /tmp/yeltnar-ansible
    nebula_ca_name: "yeltnar nebula ca"
    nebula_config_client_folder: "/etc/nebula"
    var_dir: "/var/yeltnar-nebula"
    var_dir_orch: "/var/yeltnar-nebula_orch"
    # executable_dir # is found in vars/{os_type}/{processor_arch}

  vars_files:
    - vars/{{ansible_facts.system}}/{{ansible_facts.machine}}.yml
    - vars/orchestrator.yml # this needs to be changed to reflect the OS ansible is being ran on
    - vars/other_hosts.yml

  tasks: 

    # TODO WARNING This is a copy command that depends on localhost having it
    - name: create systemd service
      copy: 
        backup: false
        dest: "/etc/systemd/system/nebula.service"
        src: "nebula.service"
      become: true

    - name: start the nebula service 
      throttle: 1
      poll: 0
      async: 5
      systemd: 
        name: nebula
        state: restarted
        enabled: true
        no_block: yes
      become: true

